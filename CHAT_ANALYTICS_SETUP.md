# Chat Analytics Daily Report Setup Guide

**Created**: 2025-10-13
**Workflow**: `chat-analytics-daily.json`
**Purpose**: Automated daily analytics reports for chatbot performance

---

## What This Workflow Does

Every day at 6 AM, this workflow automatically:

1. âœ… **Collects session statistics** (total sessions, conversions, duration)
2. âœ… **Analyzes message patterns** (total messages, avg per session)
3. âœ… **Identifies top knowledge base articles** (most used, avg similarity)
4. âœ… **Tracks common questions** (most frequent user inquiries)
5. âœ… **Monitors function calling** (order tracking, appointments, success rates)
6. âœ… **Detects knowledge gaps** (sessions with no KB matches)
7. âœ… **Stores analytics snapshot** (historical data in database)
8. âœ… **Sends Slack report** (beautiful formatted daily summary)
9. âœ… **Sends email report** (optional, disabled by default)

---

## Benefits

### Data-Driven Insights:
- âœ… Daily visibility into chatbot performance
- âœ… Identify trending questions and topics
- âœ… Track conversion rates and engagement
- âœ… See which knowledge base articles are most valuable

### Continuous Improvement:
- âœ… Detect knowledge gaps automatically
- âœ… Understand what customers ask most
- âœ… Monitor function calling reliability
- âœ… Track long-term trends

### Team Alignment:
- âœ… Everyone sees daily metrics in Slack
- âœ… No manual report generation needed
- âœ… Historical data stored for analysis
- âœ… Easy to spot anomalies

### Business Impact:
- âœ… **Data-driven decisions** (know what to optimize)
- âœ… **Better content strategy** (fill knowledge gaps)
- âœ… **Improved conversion** (identify drop-off points)
- âœ… **ROI tracking** (measure chatbot value)

---

## Setup Instructions

### Step 1: Create Analytics Table (5 min)

First, we need to create a table to store daily analytics snapshots:

```sql
-- Run this in Supabase SQL Editor
CREATE TABLE IF NOT EXISTS analytics_snapshots (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  tenant_id UUID NOT NULL REFERENCES tenants(id) ON DELETE CASCADE,
  snapshot_date DATE NOT NULL,
  snapshot_type VARCHAR(50) NOT NULL,
  data JSONB NOT NULL,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  UNIQUE(tenant_id, snapshot_date, snapshot_type)
);

-- Add index for faster queries
CREATE INDEX idx_analytics_snapshots_tenant_date 
ON analytics_snapshots(tenant_id, snapshot_date DESC);

CREATE INDEX idx_analytics_snapshots_type 
ON analytics_snapshots(snapshot_type);

-- Add RLS policies (if needed)
ALTER TABLE analytics_snapshots ENABLE ROW LEVEL SECURITY;

CREATE POLICY "Allow service role full access"
ON analytics_snapshots
FOR ALL
TO service_role
USING (true)
WITH CHECK (true);
```

### Step 2: Import Workflow to n8n (5 min)

1. **Access n8n**:
   ```
   https://n8n.nexcyte.com
   ```

2. **Create New Workflow**:
   - Click "+" (New workflow)
   - Click three dots menu â†’ "Import from File"
   - Select: `n8n/workflows/chat-analytics-daily.json`
   - Workflow imports with all nodes

3. **Review Workflow**:
   - 12 nodes total
   - Schedule trigger (6 AM daily) â†’ 6 parallel database queries â†’ merge â†’ store â†’ format â†’ send
   - Email node is disabled by default

### Step 3: Configure Credentials (10 min)

**Note**: If you already set up credentials for previous workflows, you can reuse them!

#### Supabase PostgreSQL
```
Already configured? âœ… Skip this step
Otherwise:
1. Click "Credentials" â†’ "Add Credential" â†’ "Postgres"
2. Name: "Supabase PostgreSQL"
3. Fill in connection details
4. Test Connection â†’ Save
```

#### Slack Webhook
```
Already configured? âœ… Skip this step
Otherwise:
1. Use existing webhook from previous workflows
2. Or create new webhook for #analytics channel
```

#### Resend (Email) - OPTIONAL
```
Only needed if you want email reports
Already configured? âœ… Skip this step
Otherwise: Follow Resend setup from previous guides
```

### Step 4: Customize Schedule (2 min)

The default schedule is **6 AM daily**. To change:

1. Click on "Schedule Daily at 6 AM" node
2. Modify cron expression:
   ```
   0 6 * * *    â†’ 6 AM daily
   0 9 * * *    â†’ 9 AM daily
   0 8 * * 1    â†’ 8 AM every Monday
   0 18 * * *   â†’ 6 PM daily
   ```

### Step 5: Test the Workflow (10 min)

#### Manual Test Run
```
1. Open workflow in n8n
2. Click "Execute Workflow" button (play icon)
3. Wait ~10-15 seconds for all queries to complete
4. Check execution results:
   - All 6 query nodes should show data
   - Merge node should combine all data
   - Slack message should be sent
5. Check Slack for the report
```

#### Test with Sample Data (Optional)
```bash
# If you don't have chat data yet, create sample data
psql $DATABASE_URL << 'EOF'
-- Insert sample chat session
INSERT INTO chat_sessions (id, tenant_id, user_id, status, created_at, updated_at, metadata)
VALUES 
  (gen_random_uuid(), (SELECT id FROM tenants WHERE slug = 'ezcr-01'), 
   'test-user-1', 'completed', CURRENT_DATE - INTERVAL '1 day', 
   CURRENT_DATE - INTERVAL '1 day' + INTERVAL '5 minutes', 
   '{"converted": "true"}'::jsonb);

-- Insert sample messages
INSERT INTO chat_messages (session_id, role, content, created_at)
VALUES 
  ((SELECT id FROM chat_sessions ORDER BY created_at DESC LIMIT 1), 
   'user', 'What is the weight capacity of your ramps?', 
   CURRENT_DATE - INTERVAL '1 day'),
  ((SELECT id FROM chat_sessions ORDER BY created_at DESC LIMIT 1), 
   'assistant', 'Our ramps have different weight capacities...', 
   CURRENT_DATE - INTERVAL '1 day' + INTERVAL '30 seconds');
EOF

# Now test the workflow
```

### Step 6: Activate Workflow (2 min)

1. In n8n, toggle workflow to "Active"
2. Verify schedule is enabled
3. Reports will start arriving daily at 6 AM

---

## Workflow Details

### Node Breakdown

| Node | Purpose | Execution Time |
|------|---------|----------------|
| **Schedule Trigger** | Runs daily at 6 AM | Instant |
| **Get Session Stats** | Total sessions, conversions, duration | ~1-2s |
| **Get Message Stats** | Message counts, lengths, averages | ~1-2s |
| **Get Top KB Articles** | Most used knowledge base content | ~1-2s |
| **Get Common Questions** | Most frequent user questions | ~1-2s |
| **Get Function Stats** | Order tracking & appointment calls | ~1-2s |
| **Get Knowledge Gaps** | Sessions with no KB matches | ~1-2s |
| **Merge Analytics Data** | Combines all data into report | Instant |
| **Store Analytics Snapshot** | Saves to database for history | ~1s |
| **Format Slack Message** | Creates beautiful Slack blocks | Instant |
| **Send to Slack** | Posts report to Slack channel | ~1s |
| **Send Email Report** | Optional email (disabled) | N/A |

**Total Execution Time**: ~10-15 seconds

### Data Flow

```
Schedule: 6 AM Daily
  â†“
PARALLEL QUERIES (all run simultaneously):
  â”œâ”€ Session stats (conversions, duration, unique users)
  â”œâ”€ Message stats (counts, averages)
  â”œâ”€ Top KB articles (most used, similarity)
  â”œâ”€ Common questions (frequency)
  â”œâ”€ Function calling stats (success rates)
  â””â”€ Knowledge gaps (no KB matches)
  â†“
Merge all data into single report object
  â†“
Store snapshot in analytics_snapshots table
  â†“
Format beautiful Slack message
  â†“
Send to Slack channel
  â†“
(Optional) Send email report
```

---

## Report Contents

### Slack Report Format

**Header**: ðŸ“Š Daily Chat Analytics - [Date]

**Key Metrics** (6 stat cards):
```
Total Sessions: 142
Unique Users: 98
Total Messages: 523
Avg Duration: 4.2 min
Conversion Rate: 12.7%
Conversions: 18
```

**Message Breakdown**:
- User messages: 261
- Assistant messages: 262
- Avg messages/session: 3.68

**Top Knowledge Base Articles** (Top 5):
```
1. AUN250 Product Specifications (45 uses, 92.3% similarity)
2. Shipping & Delivery Information (38 uses, 88.1% similarity)
3. Warranty Coverage Details (27 uses, 90.5% similarity)
4. Installation Instructions (22 uses, 85.7% similarity)
5. Return Policy (18 uses, 87.2% similarity)
```

**Most Common Questions** (Top 5):
```
1. "What is the weight capacity of the AUN250?" (12x)
2. "Do you offer free shipping?" (9x)
3. "How long does delivery take?" (8x)
4. "Can I return the ramp if it doesn't fit?" (7x)
5. "What's included with the ramp?" (6x)
```

**Function Calling Stats**:
```
â€¢ get_order_status: 23 calls (95.7% success)
â€¢ schedule_appointment: 8 calls (100% success)
```

**Knowledge Gaps**:
```
âš ï¸ 3 sessions had no KB matches (review recommended)
or
âœ… 0 sessions had no KB matches
```

### Email Report (Optional)

Same content as Slack but with beautiful HTML formatting:
- Professional header with gradient
- Grid layout for key metrics
- Organized sections with icons
- Alert box for knowledge gaps
- Responsive design

**To Enable Email Reports**:
1. Open workflow in n8n
2. Click "Send Email Report (Optional)" node
3. Toggle "Disabled" to OFF
4. Update recipient email address
5. Save workflow

---

## Stored Analytics Data

Each day's report is stored in `analytics_snapshots` table:

```json
{
  "date": "2025-10-13",
  "session_stats": {
    "total_sessions": 142,
    "active_sessions": 15,
    "completed_sessions": 127,
    "avg_duration_minutes": 4.23,
    "unique_users": 98,
    "conversions": 18,
    "conversion_rate": 12.68
  },
  "message_stats": {
    "total_messages": 523,
    "user_messages": 261,
    "assistant_messages": 262,
    "avg_user_msg_length": 87.45,
    "avg_assistant_msg_length": 342.18,
    "avg_messages_per_session": 3.68
  },
  "top_articles": [...],
  "common_questions": [...],
  "function_stats": [...],
  "knowledge_gaps": [...]
}
```

**Query Historical Data**:
```sql
-- Get last 30 days of analytics
SELECT 
  snapshot_date,
  data->>'session_stats' as session_stats,
  data->>'message_stats' as message_stats
FROM analytics_snapshots
WHERE tenant_id = (SELECT id FROM tenants WHERE slug = 'ezcr-01')
  AND snapshot_type = 'chat_daily'
  AND snapshot_date >= CURRENT_DATE - INTERVAL '30 days'
ORDER BY snapshot_date DESC;

-- Calculate 7-day moving average of conversions
SELECT 
  snapshot_date,
  (data->'session_stats'->>'conversions')::int as daily_conversions,
  AVG((data->'session_stats'->>'conversions')::int) OVER (
    ORDER BY snapshot_date
    ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
  ) as moving_avg_7day
FROM analytics_snapshots
WHERE tenant_id = (SELECT id FROM tenants WHERE slug = 'ezcr-01')
  AND snapshot_type = 'chat_daily'
ORDER BY snapshot_date DESC
LIMIT 30;
```

---

## Important Notes

### Query Performance

All 6 database queries run in parallel, so total time is ~2 seconds (not 12 seconds).

**If queries are slow**:
1. Ensure indexes exist on chat tables:
   ```sql
   CREATE INDEX IF NOT EXISTS idx_chat_sessions_created_at 
   ON chat_sessions(created_at);
   
   CREATE INDEX IF NOT EXISTS idx_chat_messages_created_at 
   ON chat_messages(created_at);
   
   CREATE INDEX IF NOT EXISTS idx_chat_messages_session_id 
   ON chat_messages(session_id);
   ```

2. Consider materialized views for large datasets

### Timezone Considerations

The workflow runs at 6 AM in the **n8n server's timezone**.

**To adjust**:
1. Change cron expression in schedule node
2. Or adjust date filter in SQL queries:
   ```sql
   -- Current: yesterday based on server time
   WHERE DATE(created_at) = CURRENT_DATE - INTERVAL '1 day'
   
   -- Alternative: yesterday in specific timezone
   WHERE DATE(created_at AT TIME ZONE 'America/Los_Angeles') = 
         (CURRENT_DATE AT TIME ZONE 'America/Los_Angeles') - INTERVAL '1 day'
   ```

### Handling No Data Days

If no chat sessions occurred yesterday:
- Queries will return empty results or zeros
- Report will still be sent (showing 0 sessions)
- This is expected and not an error

**To skip empty reports**:
Add a conditional node after "Get Session Stats":
```javascript
// Only continue if there were sessions
return $input.all().filter(item => 
  item.json.total_sessions > 0
);
```

### Multi-Tenant Support

The queries are already configured for multi-tenant:
```sql
WHERE cs.tenant_id = (SELECT id FROM tenants WHERE slug = 'ezcr-01')
```

**To report on multiple tenants**:
1. Duplicate the workflow for each tenant
2. Or modify queries to loop through tenants
3. Or aggregate all tenants in one report

### Knowledge Gap Detection

The workflow identifies sessions where users asked questions but no knowledge base articles matched.

**These are high-value insights** because they show:
- Topics you don't have content for
- Questions customers care about
- Opportunities to improve chatbot

**Action**: Review these sessions and create new knowledge base articles!

---

## Cost Analysis

### Per-Day Cost

| Service | Cost | Notes |
|---------|------|-------|
| Database queries | $0 | Included in Supabase |
| n8n execution | $0 | Self-hosted |
| Slack notification | $0 | Free webhook |
| Email (optional) | $0.001 | 1 email/day via Resend |
| **Total** | **~$0** | **Essentially free!** |

### Monthly Cost

```
30 days Ã— $0 = $0/month (without email)
30 days Ã— $0.001 = $0.03/month (with email)
```

**Incredibly affordable for the value!**

### Value Generated

**Time Savings**:
- Manual analytics: 30 min/day
- Automated: 0 min/day
- Savings: 15 hours/month
- Value: 15 hours Ã— $30/hr = **$450/month**

**Better Decisions**:
- Data-driven optimization
- Identify high-impact improvements
- Track ROI of changes
- Estimated value: **$200-500/month**

**Continuous Improvement**:
- Automatic knowledge gap detection
- Trending question insights
- Content strategy guidance
- Estimated value: **$300-500/month**

**Total Value**: ~$950-1,450/month
**Total Cost**: ~$0/month
**ROI**: **Infinite** (or 30,000x+ if counting email) ðŸš€

---

## Advanced Usage

### Creating Dashboards

Use stored analytics data to build dashboards:

**Metabase / Looker / Tableau**:
```sql
-- Connect to analytics_snapshots table
-- Create charts for:
-- - Daily sessions trend
-- - Conversion rate over time
-- - Top questions word cloud
-- - Function calling success rates
-- - Knowledge gap frequency
```

**Custom Dashboard in Next.js**:
```typescript
// pages/admin/analytics.tsx
async function getAnalytics(days = 30) {
  const { data } = await supabase
    .from('analytics_snapshots')
    .select('*')
    .eq('snapshot_type', 'chat_daily')
    .gte('snapshot_date', new Date(Date.now() - days * 24 * 60 * 60 * 1000))
    .order('snapshot_date', { ascending: false });
  return data;
}
```

### Weekly Summary Reports

Create a second workflow that runs weekly:

```
Schedule: Monday 8 AM
  â†“
Query last 7 days from analytics_snapshots
  â†“
Calculate week-over-week trends
  â†“
Generate executive summary
  â†“
Send to leadership team
```

### Real-Time Alerts

Add conditional nodes to send alerts:

```javascript
// After "Merge Analytics Data" node
const conversionRate = $json.session_stats.conversion_rate;
const knowledgeGaps = $json.knowledge_gaps.length;

// Alert if conversion drops below threshold
if (conversionRate < 8) {
  // Send urgent Slack alert
}

// Alert if too many knowledge gaps
if (knowledgeGaps > 10) {
  // Send content team notification
}
```

### A/B Test Tracking

Extend queries to segment by experiment groups:

```sql
SELECT
  metadata->>'ab_test_group' as test_group,
  COUNT(*) as sessions,
  AVG((metadata->>'conversion')::int) as conversion_rate
FROM chat_sessions
WHERE DATE(created_at) = CURRENT_DATE - INTERVAL '1 day'
GROUP BY test_group;
```

---

## Troubleshooting

### Issue: No Report Received

**Check**:
1. Workflow is "Active" in n8n
2. Schedule trigger is enabled
3. n8n server is running
4. Check n8n execution history for errors
5. Verify Slack webhook URL is correct

**Test Manually**: Click "Execute Workflow" button

### Issue: Query Errors

**Check**:
1. PostgreSQL credentials are correct
2. Tables exist (chat_sessions, chat_messages, etc.)
3. analytics_snapshots table was created
4. Tenant slug 'ezcr-01' exists

**Debug**: Review error message in n8n execution log

### Issue: Empty Report

**Possible Causes**:
1. No chat activity yesterday (expected)
2. Wrong date filter (timezone issue)
3. Wrong tenant_id in queries

**Fix**: Adjust date filters or tenant references

### Issue: Slack Message Too Large

If you have a very high-traffic chatbot:

**Solution**:
1. Limit top articles to 5 (already done)
2. Limit common questions to 5 (already done)
3. Or split into multiple Slack messages

---

## Next Steps

### Phase 1: Basic Setup (This Week)
- [x] Create analytics_snapshots table
- [ ] Import workflow to n8n
- [ ] Configure credentials
- [ ] Test workflow
- [ ] Activate for daily reports

### Phase 2: Optimization (Next Week)
- [ ] Review first week of reports
- [ ] Adjust schedule if needed
- [ ] Create custom Slack channel (#analytics)
- [ ] Document insights and actions

### Phase 3: Enhancement (Next Month)
- [ ] Build analytics dashboard
- [ ] Create weekly summary workflow
- [ ] Add real-time alerts for anomalies
- [ ] Integrate with other business metrics

### Phase 4: Advanced (Future)
- [ ] Predictive analytics (forecast sessions)
- [ ] Sentiment analysis on messages
- [ ] Automatic content recommendations
- [ ] A/B test result tracking

---

## Support

**n8n Documentation**: https://docs.n8n.io/
**PostgreSQL Docs**: https://www.postgresql.org/docs/
**Slack Block Kit**: https://api.slack.com/block-kit

**Need Help?**
- Check n8n execution logs first
- Review error messages in each node
- Test nodes individually
- Check database table schema
- Verify all credentials

---

**Status**: âœ… Workflow Created - Ready for Setup
**Impact**: Infinite ROI, daily visibility into chatbot performance
**Time to Deploy**: ~25 minutes
**Maintenance**: <5 min/month (just review reports)

**This workflow will give you daily insights to continuously improve your chatbot!** ðŸ“Š

---

**Document Created**: 2025-10-13
**Last Updated**: 2025-10-13
**Version**: 1.0
